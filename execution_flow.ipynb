{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando as bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "import os\n",
    "import multiprocessing\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import v_measure_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando os modulos definidos\n",
    "from src.Node import Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carregar e tratar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_name, header):\n",
    "\n",
    "    def read_csv_fle(file_name, header=0):\n",
    "        train_data = pd.read_csv(f'./data/{file_name}train.csv', header=header)\n",
    "        test_data = pd.read_csv(f'./data/{file_name}test.csv', header=header)\n",
    "        return train_data, test_data\n",
    "    \n",
    "    train_data, test_data = read_csv_fle(file_name, header)\n",
    "\n",
    "    train_labels = train_data.iloc[:, -1]\n",
    "    train_features = train_data.iloc[:, :-1]\n",
    "\n",
    "    test_labels = test_data.iloc[:, -1]\n",
    "    test_features = test_data.iloc[:, :-1]\n",
    "\n",
    "    def normalize(train_data, test_data):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_data)\n",
    "        train_data = scaler.transform(train_data)\n",
    "        test_data = scaler.transform(test_data)\n",
    "        return train_data, test_data\n",
    "    \n",
    "    train_features, test_features = normalize(train_features, test_features)\n",
    "\n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelagem dos Indivíduo e População"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gera um idividuo modelado como uma árvore aleatória... usando o método grow.\n",
    "\n",
    "Inicializa a população gerando uma lista de indivíduos aleatórios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_tree(max_depth: int, current_depth: int, terminals: list, variables:list) -> Node:\n",
    "\n",
    "    if current_depth == max_depth-1 or (current_depth > 1 and random.random() > 0.5):\n",
    "        value = random.choice(variables)\n",
    "        return Node(value)\n",
    "    else:\n",
    "        op = random.choice(terminals)\n",
    "        left_subtree = generate_random_tree(max_depth, current_depth + 1, terminals, variables)\n",
    "        right_subtree = generate_random_tree(max_depth, current_depth + 1, terminals, variables)\n",
    "        return Node(op, left_subtree, right_subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_population_grow(pop_size:int, max_depth:int, terminals:list, variables:list) -> list:\n",
    "    population = []\n",
    "    for _ in tqdm(range(pop_size),desc='Initializing population'):\n",
    "        population.append(generate_random_tree(max_depth=max_depth, current_depth=0, terminals=terminals, variables=variables))\n",
    "\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cálculo do Fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explciar cálculo da fitness através da matriz de distâncias, valor V e clusterização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fitness(individual, features, labels):\n",
    "\n",
    "    def evaluate_tree(node, example1, example2):\n",
    "        if node.is_leaf():\n",
    "            if isinstance(node.value, str):\n",
    "                return example1[node.value] - example2[node.value]\n",
    "            else:\n",
    "                return float(node.value)\n",
    "        else:\n",
    "            func = node.operators[node.value]\n",
    "            left_val = evaluate_tree(node.left, example1, example2)\n",
    "            right_val = evaluate_tree(node.right, example1, example2)\n",
    "            return func(left_val, right_val)\n",
    "\n",
    "    def compute_distance_matrix(tree, features):\n",
    "        num_examples = features.shape[0]\n",
    "        distance_matrix = np.zeros((num_examples, num_examples))\n",
    "        \n",
    "        if not isinstance(features, pd.DataFrame):\n",
    "            X = pd.DataFrame(features, columns=[f'x{i}' for i in range(features.shape[1])])\n",
    "        \n",
    "        for i in range(num_examples):\n",
    "            for j in range(i + 1, num_examples):\n",
    "                example1 = X.iloc[i].to_dict()\n",
    "                example2 = X.iloc[j].to_dict()\n",
    "                dist = evaluate_tree(tree, example1, example2)\n",
    "                distance_matrix[i, j] = abs(dist)\n",
    "                distance_matrix[j, i] = distance_matrix[i, j]\n",
    "        return distance_matrix\n",
    "\n",
    "    distance_matrix = compute_distance_matrix(individual, features)\n",
    "    \n",
    "    num_clusters = len(np.unique(labels))\n",
    "    \n",
    "    clustering = AgglomerativeClustering(n_clusters=num_clusters, metric='precomputed', linkage='average')\n",
    "    clustering.fit(distance_matrix)\n",
    "    \n",
    "    y_pred = clustering.labels_\n",
    "    fitness = v_measure_score(labels, y_pred)\n",
    "    \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness_population(population, features, labels):\n",
    "    fitness_scores = []\n",
    "    for individual in tqdm(population, total=len(population), desc='Calculating fitness'):\n",
    "        fitness = evaluate_fitness(individual, features, labels)\n",
    "        fitness_scores.append(fitness)\n",
    "    return fitness_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Operadores Genéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explciar funcionamento do crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1: Node, parent2: Node) -> tuple:\n",
    "    child1 = copy.deepcopy(parent1)\n",
    "    child2 = copy.deepcopy(parent2)\n",
    "    \n",
    "    nodes1 = child1.get_all_nodes()\n",
    "    nodes2 = child2.get_all_nodes()\n",
    "    \n",
    "    crossover_point1 = random.choice(nodes1)\n",
    "    crossover_point2 = random.choice(nodes2)\n",
    "    \n",
    "    crossover_point1.value, crossover_point2.value = crossover_point2.value, crossover_point1.value\n",
    "    crossover_point1.left, crossover_point2.left = crossover_point2.left, crossover_point1.left\n",
    "    crossover_point1.right, crossover_point2.right = crossover_point2.right, crossover_point1.right\n",
    "    \n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicar mutação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(individual, terminals, variables, max_depth):\n",
    "    mutant = copy.deepcopy(individual)\n",
    "    \n",
    "    nodes = mutant.get_all_nodes()\n",
    "    \n",
    "    mutation_point = random.choice(nodes)\n",
    "    \n",
    "    new_subtree = generate_random_tree(max_depth=max_depth, current_depth=0, terminals=terminals, variables=variables)\n",
    "    \n",
    "    mutation_point.value = new_subtree.value\n",
    "    mutation_point.left = new_subtree.left\n",
    "    mutation_point.right = new_subtree.right\n",
    "    \n",
    "    return mutant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicar seleção por torneio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population, fitness_scores, tournament_size=0):\n",
    "    selected = []\n",
    "    for _ in range(len(population)):\n",
    "        tournament = random.sample(list(zip(population, fitness_scores)), tournament_size)\n",
    "        winner = max(tournament, key=lambda x: x[1])[0]\n",
    "        selected.append(winner)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Algoritmo de GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicar o algoritmo de GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_algortihm(pop_size: int,max_depth: int,terminals: list,variables: list,generations: int,mutation_rate: float,crossover_rate: float,tournament_size: int, elitism: bool, train_labels: list,test_labels: list,train_features,test_features) -> tuple:\n",
    "    \n",
    "    history = []\n",
    "\n",
    "    population = initialize_population_grow(pop_size=pop_size, max_depth=max_depth, terminals=terminals, variables=variables)\n",
    "    \n",
    "    for generation in tqdm(range(generations), desc='Generations'):\n",
    "        population_fitness = calculate_fitness_population(population, train_features,train_labels)\n",
    "\n",
    "        best_fitness = max(population_fitness)\n",
    "\n",
    "        best_individual = population[population_fitness.index(best_fitness)]\n",
    "\n",
    "        history.append({\n",
    "                'generation': generation,\n",
    "                'best_fitness': best_fitness,\n",
    "                'min_fitness': min(population_fitness),\n",
    "                'average_fitness': np.mean(population_fitness)\n",
    "        })\n",
    "\n",
    "        new_population = []\n",
    "\n",
    "        if elitism:\n",
    "            new_population.append(best_individual)\n",
    "\n",
    "        while len(new_population) < pop_size:\n",
    "            parent1, parent2 = selection(population, population_fitness, tournament_size)\n",
    "\n",
    "            if random.random() < crossover_rate:\n",
    "                child1, child2 = crossover(parent1, parent2)\n",
    "\n",
    "            if random.random() < mutation_rate:\n",
    "                child1 = mutate(child1, terminals, variables, max_depth//2)\n",
    "                child2 = mutate(child2, terminals, variables, max_depth//2)\n",
    "\n",
    "            new_population.extend([child1, child2])\n",
    "\n",
    "        population = new_population[:pop_size]\n",
    "\n",
    "    result = {\n",
    "        'best_train_v_measure': evaluate_fitness(best_individual, train_features, train_labels),\n",
    "        'best_test_v_measure': evaluate_fitness(best_individual, test_features, test_labels),\n",
    "        'best_individual': best_individual.view_expression(),\n",
    "        'history': history\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Experimentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_as_csv(result):\n",
    "    results_dir = 'results'\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    filename = f\"experiment_{result['experiment_id']}_rep_{result['repetition']}.csv\"\n",
    "    filepath = os.path.join(results_dir, filename)\n",
    "    \n",
    "    result.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_id, repetition, pop_size, max_depth, terminals, variables, generations, mutation_rate, crossover_rate, tournament_size, elitism, train_features, train_labels, test_features, test_labels, config):\n",
    "\n",
    "    result = gp_algortihm(pop_size=pop_size, max_depth=max_depth, terminals=terminals, variables=variables, generations=generations, mutation_rate=mutation_rate, crossover_rate=crossover_rate, tournament_size=tournament_size, elitism=elitism, train_labels=train_labels, test_labels=test_labels, train_features=train_features, test_features=test_features)\n",
    "    \n",
    "    result['experiment_id'] = experiment_id\n",
    "    result['repetition'] = repetition\n",
    "    result['config'] = config\n",
    "    \n",
    "    save_result_as_csv(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_population(config):\n",
    "    pop_size = config['population_size']\n",
    "    max_depth = config['max_individual_size']\n",
    "    num_generations = config['num_generations']\n",
    "    elitism = config['elitism']\n",
    "    n_repetitions = config['n_repetitions']\n",
    "    experiment_id = config['experiment_id']\n",
    "    terminals = config['terminals']\n",
    "    variables = config['variables']\n",
    "    train_features = config['train_features']\n",
    "    train_labels = config['train_labels']\n",
    "    test_features = config['test_features']\n",
    "    test_labels = config['test_labels']\n",
    "\n",
    "    for population_size in pop_size:\n",
    "        for num_generation in num_generations:\n",
    "            crossover_prob = 0.9\n",
    "            mutation_prob = 0.05\n",
    "            tournament_size = 2\n",
    "            \n",
    "            run_config = {\n",
    "                'population_size': population_size,\n",
    "                'num_generations': num_generation,\n",
    "                'crossover_prob': crossover_prob,\n",
    "                'mutation_prob': mutation_prob,\n",
    "                'tournament_size': tournament_size,\n",
    "                'experiment_id': experiment_id,\n",
    "                'repetition': 0\n",
    "            }\n",
    "            \n",
    "            for repetition in range(n_repetitions):\n",
    "                run_config['repetition'] = repetition\n",
    "                run_experiment(experiment_id, repetition, pop_size, max_depth, terminals, variables, num_generation, mutation_prob, crossover_prob, tournament_size, elitism, train_features, train_labels, test_features, test_labels,run_config) \n",
    "            \n",
    "            experiment_id +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Rodar Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETROS DO ALGORITMO GENETICO\n",
    "\n",
    "### FIXOS ###\n",
    "TAMANHO_MAXIMO_INDIVIDUO = 7\n",
    "ELITISMO = True\n",
    "REPETICOES = 10\n",
    "TERMINAIS = ['+', '-', '*', '/']\n",
    "\n",
    "### VARIÁVEIS ###\n",
    "TAMAHO_POPULACAO = [30, 50, 100, 500]\n",
    "NUMERO_GERACOES = [30, 50, 100, 500]\n",
    "K_TORNEIO = [2,3,5,7]\n",
    "PROB_OPERADORES = [\n",
    "        {'CROSSOVER': 0.9, 'MUTATION': 0.05},\n",
    "        {'CROSSOVER': 0.6, 'MUTATION': 0.3},\n",
    "    ]\n",
    "\n",
    "# PARAMETROS DO DATASET\n",
    "WINE_FILE_NAME = 'wineRed-'\n",
    "BREAST_CANCER_FILE_NAME = 'breast_cancer_coimbra_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_train_features, wine_train_labels, wine_test_features, wine_test_labels = get_data(WINE_FILE_NAME, header=None)\n",
    "wine_variables = [f'x{i}' for i in range(len(wine_train_features[1]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Teste População"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processes = multiprocessing.cpu_count() - 1\n",
    "experiment_id = 1\n",
    "\n",
    "config = {\n",
    "    'population_size': TAMAHO_POPULACAO,\n",
    "    'max_individual_size': TAMANHO_MAXIMO_INDIVIDUO,\n",
    "    'num_generations': NUMERO_GERACOES,\n",
    "    'elitism': ELITISMO,\n",
    "    'n_repetitions': REPETICOES,\n",
    "    'experiment_id': experiment_id,\n",
    "    'terminals': TERMINAIS,\n",
    "    'variables': wine_variables,\n",
    "    'train_features': wine_train_features,\n",
    "    'train_labels': wine_train_labels,\n",
    "    'test_features': wine_test_features,\n",
    "    'test_labels': wine_test_labels\n",
    "}\n",
    "\n",
    "with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "    pool.map(run_experiment, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
