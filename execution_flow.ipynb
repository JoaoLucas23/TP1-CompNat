{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando as bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "import os\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import v_measure_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando os modulos definidos\n",
    "from src.Node import Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carregar e tratar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_name, header):\n",
    "\n",
    "    def read_csv_fle(file_name, header=0):\n",
    "        train_data = pd.read_csv(f'./data/{file_name}train.csv', header=header)\n",
    "        test_data = pd.read_csv(f'./data/{file_name}test.csv', header=header)\n",
    "        return train_data, test_data\n",
    "    \n",
    "    train_data, test_data = read_csv_fle(file_name, header)\n",
    "\n",
    "    train_labels = train_data.iloc[:, -1]\n",
    "    train_features = train_data.iloc[:, :-1]\n",
    "\n",
    "    test_labels = test_data.iloc[:, -1]\n",
    "    test_features = test_data.iloc[:, :-1]\n",
    "\n",
    "    def normalize(train_data, test_data):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(train_data)\n",
    "        train_data = scaler.transform(train_data)\n",
    "        test_data = scaler.transform(test_data)\n",
    "        return train_data, test_data\n",
    "    \n",
    "    train_features, test_features = normalize(train_features, test_features)\n",
    "\n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelagem dos Indivíduo e População"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gera um idividuo modelado como uma árvore aleatória... usando o método grow.\n",
    "\n",
    "Inicializa a população gerando uma lista de indivíduos aleatórios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_tree(max_depth: int, current_depth: int, terminals: list, variables:list) -> Node:\n",
    "\n",
    "    if current_depth == max_depth-1 or (current_depth > 1 and random.random() > 0.5):\n",
    "        value = random.choice(variables)\n",
    "        return Node(value)\n",
    "    else:\n",
    "        op = random.choice(terminals)\n",
    "        left_subtree = generate_random_tree(max_depth, current_depth + 1, terminals, variables)\n",
    "        right_subtree = generate_random_tree(max_depth, current_depth + 1, terminals, variables)\n",
    "        return Node(op, left_subtree, right_subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_population_grow(pop_size:int, max_depth:int, terminals:list, variables:list) -> list:\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        population.append(generate_random_tree(max_depth=max_depth, current_depth=0, terminals=terminals, variables=variables))\n",
    "\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cálculo do Fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explciar cálculo da fitness através da matriz de distâncias, valor V e clusterização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fitness(individual, differences, labels):\n",
    "    safe_dict = {}\n",
    "    safe_dict['operators'] = individual.operators\n",
    "    safe_dict.update(differences)\n",
    "\n",
    "    expression = individual.view_expression()\n",
    "\n",
    "    distance_matrix = eval(expression, {\"__builtins__\": None}, safe_dict)\n",
    "\n",
    "    num_clusters = len(np.unique(labels))\n",
    "    clustering = AgglomerativeClustering(n_clusters=num_clusters, metric='precomputed', linkage='average')\n",
    "    clustering.fit(distance_matrix)\n",
    "\n",
    "    y_pred = clustering.labels_\n",
    "    fitness = v_measure_score(labels, y_pred)\n",
    "\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_differences(features):\n",
    "    X = pd.DataFrame(features, columns=[f'x{i}' for i in range(features.shape[1])])\n",
    "    differences = {}\n",
    "    for feature in X.columns:\n",
    "        differences[feature] = X[feature].values[:, np.newaxis] - X[feature].values[np.newaxis, :]\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness_population(population, features, labels):\n",
    "    differences = compute_differences(features)\n",
    "\n",
    "    fitness_scores = []\n",
    "    for individual in population:\n",
    "        fitness = evaluate_fitness(individual, differences, labels)\n",
    "        fitness_scores.append(fitness)\n",
    "    return fitness_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Operadores Genéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explciar funcionamento do crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1: Node, parent2: Node) -> tuple:\n",
    "    child1 = copy.deepcopy(parent1)\n",
    "    child2 = copy.deepcopy(parent2)\n",
    "    \n",
    "    nodes1 = child1.get_all_nodes()\n",
    "    nodes2 = child2.get_all_nodes()\n",
    "    \n",
    "    crossover_point1 = random.choice(nodes1)\n",
    "    crossover_point2 = random.choice(nodes2)\n",
    "    \n",
    "    crossover_point1.value, crossover_point2.value = crossover_point2.value, crossover_point1.value\n",
    "    crossover_point1.left, crossover_point2.left = crossover_point2.left, crossover_point1.left\n",
    "    crossover_point1.right, crossover_point2.right = crossover_point2.right, crossover_point1.right\n",
    "    \n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicar mutação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(individual, terminals, variables, max_depth):\n",
    "    mutant = copy.deepcopy(individual)\n",
    "    \n",
    "    nodes = mutant.get_all_nodes()\n",
    "    \n",
    "    mutation_point = random.choice(nodes)\n",
    "    \n",
    "    new_subtree = generate_random_tree(max_depth=max_depth, current_depth=0, terminals=terminals, variables=variables)\n",
    "    \n",
    "    mutation_point.value = new_subtree.value\n",
    "    mutation_point.left = new_subtree.left\n",
    "    mutation_point.right = new_subtree.right\n",
    "    \n",
    "    return mutant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicar seleção por torneio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population, fitness_scores, tournament_size=0):\n",
    "    selected = []\n",
    "    for _ in range(2):  # Seleciona dois indivíduos\n",
    "        tournament = random.sample(list(zip(population, fitness_scores)), tournament_size)\n",
    "        winner = max(tournament, key=lambda x: x[1])[0]\n",
    "        selected.append(winner)\n",
    "    return selected[0], selected[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Algoritmo de GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicar o algoritmo de GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_algortihm(pop_size: int,max_depth: int,terminals: list,variables: list,generations: int,mutation_rate: float,crossover_rate: float,tournament_size: int, elitism: bool, train_labels: list,test_labels: list,train_features,test_features) -> tuple:\n",
    "    \n",
    "    history = []\n",
    "\n",
    "    population = initialize_population_grow(pop_size=pop_size, max_depth=max_depth, terminals=terminals, variables=variables)\n",
    "    \n",
    "    for generation in tqdm(range(generations), desc='Generations'):\n",
    "        population_fitness = calculate_fitness_population(population, train_features,train_labels)\n",
    "\n",
    "        best_fitness = max(population_fitness)\n",
    "\n",
    "        best_individual = population[population_fitness.index(best_fitness)]\n",
    "\n",
    "        history.append({\n",
    "                'generation': generation,\n",
    "                'best_fitness': best_fitness,\n",
    "                'min_fitness': min(population_fitness),\n",
    "                'average_fitness': np.mean(population_fitness)\n",
    "        })\n",
    "\n",
    "        new_population = []\n",
    "\n",
    "        if elitism:\n",
    "            new_population.append(best_individual)\n",
    "\n",
    "        while len(new_population) < pop_size:\n",
    "            parent1, parent2 = selection(population, population_fitness, tournament_size)\n",
    "\n",
    "            child1, child2 = copy.deepcopy(parent1), copy.deepcopy(parent2)\n",
    "\n",
    "            if random.random() < crossover_rate:\n",
    "                child1, child2 = crossover(parent1, parent2)\n",
    "\n",
    "            if random.random() < mutation_rate:\n",
    "                child1 = mutate(child1, terminals, variables, max_depth//2)\n",
    "                child2 = mutate(child2, terminals, variables, max_depth//2)\n",
    "\n",
    "            new_population.extend([child1, child2])\n",
    "\n",
    "        population = new_population[:pop_size]\n",
    "\n",
    "    train_diff = compute_differences(train_features)\n",
    "    test_diff = compute_differences(test_features)\n",
    "\n",
    "    best_fitness_train = evaluate_fitness(best_individual, train_diff, train_labels)\n",
    "    best_fitness_test = evaluate_fitness(best_individual, test_diff, test_labels)\n",
    "\n",
    "    return {\n",
    "        'best_train_v_measure': best_fitness_train,\n",
    "        'best_test_v_measure': best_fitness_test,\n",
    "        'best_individual': best_individual.view_expression(),\n",
    "        'history': history\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Experimentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_as_csv(result):\n",
    "    results_dir = 'results'\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    filename = f\"history_experiment_{result['experiment_id']}_rep_{result['repetition']}.json\"\n",
    "    filepath = os.path.join(results_dir, filename)\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(result, f, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_id, repetition, pop_size, max_depth, generations, mutation_rate, crossover_rate, tournament_size, elitism, config):\n",
    "\n",
    "    terminals = ['+', '-', '*', '/']\n",
    "\n",
    "    train_features, train_labels, test_features, test_labels = get_data('wineRed-', header=None)\n",
    "    variables = [f'x{i}' for i in range(len(train_features[1]))]\n",
    "\n",
    "    result = gp_algortihm(pop_size=pop_size, max_depth=max_depth, terminals=terminals, variables=variables, generations=generations, mutation_rate=mutation_rate, crossover_rate=crossover_rate, tournament_size=tournament_size, elitism=elitism, train_labels=train_labels, test_labels=test_labels, train_features=train_features, test_features=test_features)\n",
    "    \n",
    "    result['experiment_id'] = experiment_id\n",
    "    result['repetition'] = repetition\n",
    "    result['config'] = config\n",
    "    \n",
    "    result['history'] = result['history']\n",
    "\n",
    "    save_result_as_csv(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_processes(tf, tl, tef, tel):\n",
    "    global train_features, train_labels, test_features, test_labels\n",
    "    train_features = tf\n",
    "    train_labels = tl\n",
    "    test_features = tef\n",
    "    test_labels = tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import logging\n",
    "import threading\n",
    "from queue import Queue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_safe(experiment_id, repetition, population_size, max_depth, num_generation, mutation_prob, \n",
    "                        crossover_prob, tournament_size, elitism):\n",
    "    try:\n",
    "        # Set up run_config within this function\n",
    "        run_config = {\n",
    "            'population_size': population_size,\n",
    "            'num_generations': num_generation,\n",
    "            'crossover_prob': crossover_prob,\n",
    "            'mutation_prob': mutation_prob,\n",
    "            'tournament_size': tournament_size,\n",
    "            'experiment_id': experiment_id,\n",
    "            'repetition': repetition\n",
    "        }\n",
    "\n",
    "        logging.info(f\"Starting experiment {experiment_id}, repetition {repetition}\")\n",
    "        \n",
    "        # Call the original function\n",
    "        run_experiment(experiment_id, repetition, population_size, max_depth, \n",
    "                       num_generation, mutation_prob, crossover_prob, tournament_size, elitism, \n",
    "                       run_config)\n",
    "        \n",
    "        logging.info(f\"Completed experiment {experiment_id}, repetition {repetition}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in experiment {experiment_id}, repetition {repetition}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_parallel(experiment_id, n_repetitions, population_size, max_depth, num_generation, \n",
    "                            mutation_prob, crossover_prob, tournament_size, elitism):\n",
    "    threads = []\n",
    "    progress_queue = Queue()\n",
    "\n",
    "    # Start each repetition in a new thread\n",
    "    for repetition in range(n_repetitions):\n",
    "        thread = threading.Thread(\n",
    "            target=lambda q, *args: (run_experiment_safe(*args), q.put(repetition)),  # Queue progress after completion\n",
    "            args=(progress_queue, experiment_id, repetition, population_size, max_depth, num_generation, \n",
    "                  mutation_prob, crossover_prob, tournament_size, elitism)\n",
    "        )\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    \n",
    "    # Display progress with tqdm\n",
    "    for _ in range(n_repetitions):\n",
    "        progress_queue.get()  # Wait for each repetition to complete\n",
    "\n",
    "    # Ensure all threads have completed\n",
    "    for thread in threads:\n",
    "        thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_population(config):\n",
    "\n",
    "    pop_size = config['population_size']\n",
    "    max_depth = config['max_individual_size']\n",
    "    num_generations = config['num_generations']\n",
    "    elitism = config['elitism']\n",
    "    n_repetitions = config['n_repetitions']\n",
    "    experiment_id = config['experiment_id']\n",
    "\n",
    "    for population_size in tqdm(pop_size, desc='Population Size'):\n",
    "        for num_generation in tqdm(num_generations, desc='Number of Generations'):\n",
    "            crossover_prob = 0.9\n",
    "            mutation_prob = 0.05\n",
    "            tournament_size = 2\n",
    "            \n",
    "            run_experiment_parallel(experiment_id, n_repetitions, population_size, max_depth, num_generation, mutation_prob, crossover_prob, tournament_size, elitism)\n",
    "\n",
    "            experiment_id +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Rodar Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETROS DO ALGORITMO GENETICO\n",
    "\n",
    "### FIXOS ###\n",
    "TAMANHO_MAXIMO_INDIVIDUO = 7\n",
    "ELITISMO = True\n",
    "REPETICOES = 10\n",
    "TERMINAIS = ['+', '-', '*', '/']\n",
    "\n",
    "### VARIÁVEIS ###\n",
    "TAMAHO_POPULACAO = [30, 50, 100, 500]\n",
    "NUMERO_GERACOES = [30, 50, 100, 500]\n",
    "K_TORNEIO = [2,3,5,7]\n",
    "PROB_OPERADORES = [\n",
    "        {'CROSSOVER': 0.9, 'MUTATION': 0.05},\n",
    "        {'CROSSOVER': 0.6, 'MUTATION': 0.3},\n",
    "    ]\n",
    "\n",
    "# PARAMETROS DO DATASET\n",
    "WINE_FILE_NAME = 'wineRed-'\n",
    "BREAST_CANCER_FILE_NAME = 'breast_cancer_coimbra_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Teste População"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33173b1882f04895a24bcd53c5cbfd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Population Size:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b41c599d714a51997025e7d622eafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Number of Generations:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc101281ce494c7f8aec730a1488fa68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repetitions:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829bc9ec4c4941fca517b22f53bdbf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87200daadeed4b298a99d7e2027af755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d309459717dc467a9bf2673ed3476566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d90618fb96e44b399c64abfd431c937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dea570edcdd46b38b285d21897ee997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68cf0b995c244bf490061be9399d198e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc818658e0d4d2b88d1ac8c03a2b8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29d5c42e3ab4b00bde9f323ab82e1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52527cc860584e6cb2878a87262abab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26df2097cc44891a5117ae198921737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27efcd231a84fd096de1d53b3c31040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repetitions:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029093f46e8b4736b215366127f83b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328bcb7e2dbf452c8872c4a77b5e9a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fddc2f44f4a4db69de26f2e24d0b43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7b832694624a2d8867c65292b0584b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961324c266f441358e9e3165020d4b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8abaa99cf94dd9bdf4643a38dad6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b1e32f46564331abae689240251b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942963f1da344a4e8af4edb9d0588841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5543b457766c418d9e264415ebf4e925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5623d7d61a43bb959dec475421a200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_id = 1\n",
    "\n",
    "config = {\n",
    "    'population_size': TAMAHO_POPULACAO,\n",
    "    'max_individual_size': TAMANHO_MAXIMO_INDIVIDUO,\n",
    "    'num_generations': NUMERO_GERACOES,\n",
    "    'elitism': ELITISMO,\n",
    "    'n_repetitions': REPETICOES,\n",
    "    'experiment_id': experiment_id\n",
    "}\n",
    "\n",
    "test_population(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
